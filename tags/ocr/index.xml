<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ocr on Andy Ibanez</title><link>https://www.andyibanez.com/tags/ocr/</link><description>Recent content in Ocr on Andy Ibanez</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Wed, 10 Jun 2020 07:00:00 -0400</lastBuildDate><atom:link href="https://www.andyibanez.com/tags/ocr/index.xml" rel="self" type="application/rss+xml"/><item><title>Document Scanning and Text Recognition With Vision and VisionKit on iOS</title><link>https://www.andyibanez.com/posts/scanning-and-text-recognition-with-visionkit/</link><pubDate>Wed, 10 Jun 2020 07:00:00 -0400</pubDate><guid>https://www.andyibanez.com/posts/scanning-and-text-recognition-with-visionkit/</guid><description>&lt;p>It is amazing what we can do with smartphones these days. Document scanning and text recognition are nothing new. But being able to have such a functionality in our pockets is pretty neat. These days we can create apps that have such features very quickly thanks to the push Apple has been doing to promote Machine Learning and Artificial Intelligence on their devices.&lt;/p>
&lt;p>Starting on iOS 11, we can natively scan documents with a system framework called VisionKit, and we can perform operations on images using a framework called Vision. It wasn&amp;rsquo;t until iOS 13 that we finally had the ability to recognize text on images ourselves using the Vision framework, without leveraging third party libraries. In this article we will explore how we can use the VisionKit framework to scan documents and the Vision framework to detect text as two separate tasks, so you can see how easy these two tasks are and you can learn to put them together.&lt;/p></description></item></channel></rss>